# Enhancing Adversarial Transferability by Resolving Gradient Conflicts in Multi-Input Transformations
Adversarial examples mislead deep neural networks by introducing imperceptible perturbations to images, and their transferability enables examples crafted on surrogate model to successfully attack unseen models. Studying this transferability can help to improve defense mechanisms in deep learning systems. Transformation-based input attacks are among the leading strategies for improving transferability. These methods apply various transformations to the original image to generate multiple augmented copies and aggregate their gradients in the surrogate model to iteratively produce more universally effective perturbations. Recent work has further boosted transferability by combining multiple transformations in parallel at each iteration. However, aggregating gradients from these transformed copies introduces gradient conflicts, weakening the dominant gradient and disrupting the perturbation optimization update trajectory. This causes the trajectory to deviate from the direction that maximizes the transferability of adversarial perturbations, leading to overfitting to the surrogate model and reducing its transferability to other models. Although diversity of multi-transformation combinations preserves adversarial efficacy between different views and scales, gradient conflicts remains a major bottleneck. To preserve diversity while resolving such conflicts, we propose a two‑phase framework:
Phase I involves precomputation in which gradients from multiple transformed copies are aggregated to build a composite momentum vector directed toward regions of high generalizability.
Phase II initializes at the clean example by inheriting the composite momentum accumulated in Phase I. Starting from this momentum and reinforcing the dominant gradient direction, the perturbation is iteratively refined to achieve higher cross-model attack success rates.
Extensive experiments demonstrate that our method outperforms existing approaches in both convolutional neural network and transformer architectures, maintaining attack performance under common defense mechanisms and exhibiting strong generalization on real‑world multimodal platforms.
![1 3](https://github.com/user-attachments/assets/ed897b1a-7421-4b85-bd05-73312be6784f)
